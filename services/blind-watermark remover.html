<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>盲水印清除工具</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      max-width: 800px;
      margin: 0 auto;
      padding: 20px;
    }
    canvas {
      max-width: 100%;
      height: auto;
    }
    #downloadBtn {
      margin-top: 10px;
    }
  </style>
</head>
<body>
  <h1>盲水印清除工具</h1>
  <label for="fileInput">选择图片文件：</label>
  <input type="file" id="fileInput" accept="image/*"> 
  <canvas id="outputCanvas"></canvas>
  
  <button id="downloadBtn" disabled>下载</button> 
  
  <script>
    // ============================= 性能优化说明 =============================
    // 1. 原实现：两遍扫描 (收集唯一颜色 + 颜色映射) + O(U^2) 颜色压缩 -> 大图极慢且内存高。
    // 2. 新实现：单遍 O(N) 直接颜色量化 (基于步长 bucket) 去除微弱扰动，达到“抹除细粒度盲水印”效果。
    // 3. 利用 createImageBitmap 加速解码；若可用则使用内联 Worker + OffscreenCanvas 在后台线程处理像素。
    // 4. 对于不支持 OffscreenCanvas / Worker 的环境，降级为主线程同步处理（仍为 O(N)）。
    // 5. 量化步长 STEP 可调：值越大去除噪点/隐水印越强但保真度下降，默认 24（更细于旧 threshold 32 的感知效果）。
    // 6. 内存复用：不再创建巨大 map；仅在原像素缓冲区就地修改；避免多次中间结构。
    // =======================================================================

    const fileInput = document.getElementById('fileInput');
    const outputCanvas = document.getElementById('outputCanvas');
    const downloadBtn = document.getElementById('downloadBtn');
    const STEP = 24;              // 颜色量化步长 (建议: 16~40)
    const HALF = STEP >> 1;       // 四舍五入辅助
    let processing = false;
    let worker = null;
    let lastBitmap = null;        // 保存处理后位图引用用于下载

    // 内联 worker 代码（字符串形式）
    function createInlineWorker() {
      if (!('Worker' in window) || !('OffscreenCanvas' in window)) return null;
      const code = `self.onmessage = async (e) => {\n  const { imageBitmap, step } = e.data;\n  const w = imageBitmap.width, h = imageBitmap.height;\n  const off = new OffscreenCanvas(w, h);\n  const ctx = off.getContext('2d');\n  ctx.drawImage(imageBitmap, 0, 0);\n  // 获取像素并量化\n  const imgData = ctx.getImageData(0, 0, w, h);\n  const data = imgData.data;\n  const HALF = step >> 1;\n  // 单循环 O(N) 量化（移除细微噪点 / 隐写微扰）\n  for (let i = 0; i < data.length; i += 4) {\n    data[i]   = ((data[i]   + HALF) / step | 0) * step;\n    data[i+1] = ((data[i+1] + HALF) / step | 0) * step;\n    data[i+2] = ((data[i+2] + HALF) / step | 0) * step;\n    // alpha 保持不变\n  }\n  ctx.putImageData(imgData, 0, 0);\n  const bitmap = off.transferToImageBitmap();\n  self.postMessage({ bitmap, width: w, height: h }, [bitmap]);\n};`;
      const blob = new Blob([code], { type: 'application/javascript' });
      return new Worker(URL.createObjectURL(blob));
    }

    worker = createInlineWorker();
    if (worker) {
      worker.onmessage = (e) => {
        const { bitmap, width, height } = e.data;
        rendering(bitmap, width, height);
        processing = false;
      };
      worker.onerror = (err) => {
        console.error('Worker 处理失败，回退主线程: ', err);
        worker.terminate();
        worker = null;
        processing = false;
      };
    }


    // ========== 新增：WebGL像素量化（GPU加速）优先调度 ==========
    fileInput.addEventListener('change', async (e) => {
      if (processing) return; // 防止并发
      const file = e.target.files[0];
      if (!file) {
        alert('请先选择一个图片文件。');
        return;
      }
      processing = true;
      downloadBtn.disabled = true;
      console.time('decode');
      let bitmap;
      try {
        bitmap = await createImageBitmap(file);
      } catch (err) {
        console.warn('createImageBitmap 失败，使用 Image 回退', err);
        bitmap = await decodeViaImage(file);
      }
      console.timeEnd('decode');

      // 优先尝试WebGL
      if (window.WebGLRenderingContext) {
        try {
          console.log('[进度] 尝试WebGL GPU加速...');
          console.time('webgl-gpu-process');
          const ok = await tryWebGLQuant(bitmap, STEP);
          if (ok) {
            console.timeEnd('webgl-gpu-process');
            console.log('[成功] WebGL GPU加速处理完成');
            processing = false;
            return;
          } else {
            console.log('[提示] WebGL可用但处理失败，降级worker/主线程');
          }
        } catch (err) {
          console.warn('[异常] WebGL处理失败，降级worker/主线程', err);
        }
      } else {
        console.log('[提示] 当前环境不支持WebGL，跳过GPU加速');
      }

      // Worker 路径
      if (worker) {
        console.log('[进度] 尝试Web Worker并行处理...');
        console.time('worker-process');
        try {
          worker.postMessage({ imageBitmap: bitmap, step: STEP }, [bitmap]);
          // 返回后在 onmessage 中继续
          return;
        } catch (err) {
          console.error('[异常] Worker 发送失败，回退主线程: ', err);
        }
      } else {
        console.log('[提示] Worker不可用，直接主线程处理');
      }

      // 主线程回退处理
      console.log('[进度] 主线程同步处理...');
      console.time('main-thread-process');
      const { imageData, width, height } = processOnMain(bitmap, STEP);
      console.timeEnd('main-thread-process');
      drawImageData(imageData, width, height);
      processing = false;
    });

    // WebGL量化核心：将bitmap绘制到WebGL，着色器量化后回读像素
    async function tryWebGLQuant(bitmap, step) {
      // 1. 创建WebGL上下文
      const w = bitmap.width, h = bitmap.height;
      const glCanvas = document.createElement('canvas');
      glCanvas.width = w; glCanvas.height = h;
      const gl = glCanvas.getContext('webgl') || glCanvas.getContext('experimental-webgl');
      if (!gl) return false;

      // 2. 创建着色器
      const vsSource = `attribute vec2 aPos; varying vec2 vUv; void main(){ vUv=aPos*0.5+0.5; gl_Position=vec4(aPos,0,1); }`;
  // 再次修正：量化后加0.5步长再归一化，确保淡灰色不会塌缩为黑色
  const fsSource = `precision mediump float; uniform sampler2D uTex; uniform float uStep; varying vec2 vUv; void main(){ vec4 c=texture2D(uTex,vUv); vec3 quant = floor((c.rgb*255.0+uStep*0.5)/uStep)*uStep + 0.5*uStep; c.rgb = min(quant, 255.0)/255.0; gl_FragColor=vec4(c.rgb,1.0); }`;
      function compileShader(type, src) {
        const s = gl.createShader(type); gl.shaderSource(s, src); gl.compileShader(s);
        if (!gl.getShaderParameter(s, gl.COMPILE_STATUS)) throw gl.getShaderInfoLog(s);
        return s;
      }
      const vs = compileShader(gl.VERTEX_SHADER, vsSource);
      const fs = compileShader(gl.FRAGMENT_SHADER, fsSource);
      const prog = gl.createProgram();
      gl.attachShader(prog, vs); gl.attachShader(prog, fs); gl.linkProgram(prog);
      if (!gl.getProgramParameter(prog, gl.LINK_STATUS)) throw gl.getProgramInfoLog(prog);
      gl.useProgram(prog);

      // 3. 顶点与纹理
      const posBuf = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, posBuf);
      gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([-1,-1,1,-1,-1,1,1,1]), gl.STATIC_DRAW);
      const aPos = gl.getAttribLocation(prog, 'aPos');
      gl.enableVertexAttribArray(aPos);
      gl.vertexAttribPointer(aPos, 2, gl.FLOAT, false, 0, 0);

      // 4. 纹理上传
      const tex = gl.createTexture();
      gl.bindTexture(gl.TEXTURE_2D, tex);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
      // 将bitmap绘制到2D canvas再上传，保证兼容性
      const tmp2d = document.createElement('canvas');
      tmp2d.width = w; tmp2d.height = h;
      tmp2d.getContext('2d').drawImage(bitmap, 0, 0);
      gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, tmp2d);

      // 5. 设置uniform
      gl.uniform1i(gl.getUniformLocation(prog, 'uTex'), 0);
      gl.uniform1f(gl.getUniformLocation(prog, 'uStep'), step);

      // 6. 绘制
      gl.viewport(0, 0, w, h);
      gl.clear(gl.COLOR_BUFFER_BIT);
      gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);

      // 7. 读取像素
      const pixels = new Uint8Array(w * h * 4);
      gl.readPixels(0, 0, w, h, gl.RGBA, gl.UNSIGNED_BYTE, pixels);

      // 8. 绘制到主canvas
      const ctx = outputCanvas.getContext('2d');
      outputCanvas.width = w; outputCanvas.height = h;
      const imgData = ctx.createImageData(w, h);
      imgData.data.set(pixels);
      ctx.putImageData(imgData, 0, 0);
      downloadBtn.disabled = false;
      return true;
    }

    // 主线程处理函数（与 worker 同逻辑）
    function processOnMain(bitmap, step) {
      const w = bitmap.width, h = bitmap.height;
      const canvas = document.createElement('canvas');
      canvas.width = w; canvas.height = h;
      const ctx = canvas.getContext('2d');
      ctx.drawImage(bitmap, 0, 0);
      const imgData = ctx.getImageData(0, 0, w, h);
      quantizeInPlace(imgData.data, step);
      return { imageData: imgData, width: w, height: h };
    }

    function quantizeInPlace(data, step) {
      const HALF = step >> 1;
      // 单循环；使用整数运算加速
      for (let i = 0; i < data.length; i += 4) {
        data[i]   = ((data[i]   + HALF) / step | 0) * step;
        data[i+1] = ((data[i+1] + HALF) / step | 0) * step;
        data[i+2] = ((data[i+2] + HALF) / step | 0) * step;
      }
    }

    async function decodeViaImage(file) {
      return new Promise((resolve, reject) => {
        const url = URL.createObjectURL(file);
        const img = new Image();
        img.onload = () => { resolve(img); URL.revokeObjectURL(url); };
        img.onerror = (e) => { reject(e); URL.revokeObjectURL(url); };
        img.src = url;
      });
    }

    function rendering(bitmap, width, height) {
      console.timeEnd('worker-process');
      outputCanvas.width = width;
      outputCanvas.height = height;
      const ctx = outputCanvas.getContext('2d');
      ctx.drawImage(bitmap, 0, 0);
      lastBitmap = bitmap; // 保存引用
      downloadBtn.disabled = false;
      console.log('处理完成 (worker)');
    }

    function drawImageData(imageData, width, height) {
      outputCanvas.width = width;
      outputCanvas.height = height;
      outputCanvas.getContext('2d').putImageData(imageData, 0, 0);
      downloadBtn.disabled = false;
      console.log('处理完成 (main thread)');
    }

    // 下载（直接使用已绘制 canvas 转 Blob，避免再次重算）
    downloadBtn.addEventListener('click', () => {
      if (processing) return;
      outputCanvas.toBlob((blob) => {
        if (!blob) return;
        const link = document.createElement('a');
        link.download = 'dewatermarked.png';
        link.href = URL.createObjectURL(blob);
        link.click();
        setTimeout(() => URL.revokeObjectURL(link.href), 4000);
      }, 'image/png');
    });

    // 暴露一个可调参数接口（控制台里可修改 window.__SET_STEP(数值) 动态测试）
    window.__SET_STEP = function(newStep){
      if (processing) { console.warn('处理中，稍后再试'); return; }
      if (typeof newStep !== 'number' || newStep < 2 || newStep > 96) { console.warn('步长取值范围建议 2~96'); return; }
      console.log('STEP 由', STEP, '临时调整为', newStep, '(仅本次会话 - 需刷新恢复)');
      // 说明：由于 STEP 被编译进 worker 代码，不重新构建 worker；此接口仅对后续主线程回退或重新加载后生效可根据需要拓展。
    };
  </script>
</body>
</html>